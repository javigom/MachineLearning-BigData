{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as skl\n",
    "\n",
    "from pandas.io.parsers import read_csv\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_name):\n",
    "    # CSV to DataFrame\n",
    "    data = read_csv(file_name).to_numpy()\n",
    "    return data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_csv('data/processed/train_processed.csv')\n",
    "validation = load_csv('data/processed/validation_processed.csv')\n",
    "test = load_csv('data/processed/test_processed.csv')\n",
    "X_train = train[:,:-1]\n",
    "y_train = train[:,-1]\n",
    "X_validation = validation[:,:-1]\n",
    "y_validation = validation[:,-1]\n",
    "X_test = test[:,:-1]\n",
    "y_test = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el valor de la función sigmoide\n",
    "def sigmoid(X):\n",
    "    z = 1/(1 + np.exp(-X))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagación hacia delante\n",
    "def forward_propagation(Theta1, Theta2, X):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    # Input Layer\n",
    "    a1 = np.hstack([np.ones([m, 1]), X])\n",
    "    # Hidden Layer\n",
    "    z2 = np.matmul(a1, Theta1.T)\n",
    "    a2 = np.hstack([np.ones([m, 1]), sigmoid(z2)])\n",
    "    # Output Layer\n",
    "    z3 = np.matmul(a2, Theta2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    return a1, a2, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de coste\n",
    "def cost(Theta1, Theta2, X, y):\n",
    "    a1, a2, H = forward_propagation(Theta1, Theta2, X)\n",
    "    Term1 = y * np.log(H)\n",
    "    Term2 =  (1 - y) * np.log(1 - H)\n",
    "    coste = (- 1 / (len(y))) * np.sum(Term1 + Term2)\n",
    "\n",
    "    return coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de coste con regularización\n",
    "def cost_reg(Theta1, Theta2, X, y, lam):\n",
    "    coste = cost(Theta1, Theta2, X, y)\n",
    "    Term3 = np.sum(np.square(Theta1[:,1:])) + np.sum(np.square(Theta2[:,1:]))     \n",
    "    coste += (lam / (2 * len(y))) * Term3\n",
    "    \n",
    "    return coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que calcula la propagación hacia atrás\n",
    "def back_propagation(params_rn, num_entradas, num_ocultas, num_etiquetas, X, y, reg):\n",
    "    \n",
    "    # backprop devuelve una tupla (coste, gradiente) con el coste y el gradiente de\n",
    "    # una red neuronal de tres capas, con num_entradas, num_ocultas nodos en la capa\n",
    "    # oculta y num_etiquetas nodos en la capa de salida. Si m es el número de ejemplos\n",
    "    # de entrenamiento, la dimensión de ’X’ es (m, num_entradas) y la de ’y’ es\n",
    "    # (m, num_etiquetas)\n",
    "    \n",
    "    # Theta1 y Theta2 están codificados como un array unidimensional\n",
    "    Theta1 = np.reshape(params_rn[:num_ocultas * (num_entradas + 1)], (num_ocultas, (num_entradas + 1)))\n",
    "    Theta2 = np.reshape(params_rn[num_ocultas * (num_entradas + 1):], (num_etiquetas, (num_ocultas + 1)))\n",
    "    \n",
    "    m = len(y)\n",
    "    \n",
    "    # Matrices para almacenar el gradiente con las mismas dimensiones que Theta1 y Theta2\n",
    "    Delta1 = np.zeros(np.shape(Theta1))\n",
    "    Delta2 = np.zeros(np.shape(Theta2))\n",
    "    \n",
    "    # Propagación hacia delante\n",
    "    a1, a2, H = forward_propagation(Theta1, Theta2, X)\n",
    "    \n",
    "    # Contribución de cada nodo al error de la salida\n",
    "    d3 = H - y\n",
    "    d2 = (np.dot(d3,Theta2) * (a2 * (1 - a2)))[:,1:]  \n",
    "    Delta1 = np.dot(d2.T, a1)\n",
    "    Delta2 = np.dot(d3.T, a2)\n",
    "    \n",
    "    # Añadimos regularización\n",
    "    Delta1 = Delta1/m\n",
    "    Delta2 = Delta2/m\n",
    "    Delta1[:,1:] = Delta1[:,1:] + (reg/m)*Theta1[:,1:]\n",
    "    Delta2[:,1:] = Delta2[:,1:] + (reg/m)*Theta2[:,1:]\n",
    "    \n",
    "    # Devolvemos el coste y el gradiente\n",
    "    coste = cost_reg(Theta1, Theta2, X, y,reg)\n",
    "    grad = np.concatenate((np.ravel(Delta1),np.ravel(Delta2)))\n",
    "    \n",
    "    return coste, grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena una red neuronal con reg como término de regularización y num_iters como número de iteraciones\n",
    "def training(reg, num_iters):\n",
    "    \n",
    "    # Entrenamos la red neuronal\n",
    "    fmin = minimize(fun=back_propagation, x0=params_rn,\n",
    "                args=(num_entradas, num_ocultas,\n",
    "                num_etiquetas, X, y_onehot, reg),\n",
    "                method='TNC', jac=True,\n",
    "                options={'maxiter': num_iters})\n",
    "\n",
    "    # Reordenamos Theta1 y Theta2\n",
    "    Theta1 = np.reshape(fmin.x[:num_ocultas*(num_entradas + 1)],(num_ocultas,(num_entradas + 1)))\n",
    "    Theta2 = np.reshape(fmin.x[num_ocultas * (num_entradas+1):],(num_etiquetas,(num_ocultas + 1)))\n",
    "    result = forward_propagation(Theta1,Theta2, X)[2]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
